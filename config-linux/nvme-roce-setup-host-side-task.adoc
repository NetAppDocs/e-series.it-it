---
permalink: config-linux/nvme-roce-setup-host-side-task.html 
sidebar: sidebar 
keywords: express linux configuration, software configuration, linux host, E2800, E5700, EF300, EF600, E-Series, eseries 
summary: 'La configurazione di NVMe Initiator in un ambiente RoCE include l"installazione e la configurazione dei pacchetti rdma-core e nvme-cli, la configurazione degli indirizzi IP dell"iniziatore e l"impostazione del layer NVMe-of sull"host.' 
---
= Configurare l'iniziatore NVMe su RoCE sull'host in e-Series - Linux
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
La configurazione di NVMe Initiator in un ambiente RoCE include l'installazione e la configurazione dei pacchetti rdma-core e nvme-cli, la configurazione degli indirizzi IP dell'iniziatore e l'impostazione del layer NVMe-of sull'host.

.Prima di iniziare
È necessario utilizzare il sistema operativo RHEL 7, RHEL 8, RHEL 9, SUSE Linux Enterprise Server 12 o 15 Service Pack più recente. Vedere https://mysupport.netapp.com/matrix["Tool di matrice di interoperabilità NetApp"^] per un elenco completo dei requisiti più recenti.

.Fasi
. Installare i pacchetti rdma e nvme-cli:
+
*SLES 12 o SLES 15*

+
[listing]
----

# zypper install rdma-core
# zypper install nvme-cli
----
+
*RHEL 7, RHEL 8 E RHEL 9*

+
[listing]
----

# yum install rdma-core
# yum install nvme-cli
----
. Per RHEL 8 e RHEL 9, installare gli script di rete:
+
*RHEL 8*

+
[listing]
----
# yum install network-scripts
----
+
*RHEL 9*

+
[listing]
----
# yum install NetworkManager-initscripts-updown
----
. Ottenere l'NQN host, che verrà utilizzato per configurare l'host in un array.
+
[listing]
----
# cat /etc/nvme/hostnqn
----
. Impostare gli indirizzi IP IPv4 sulle porte ethernet utilizzate per collegare NVMe su RoCE. Per ciascuna interfaccia di rete, creare uno script di configurazione che contenga le diverse variabili per tale interfaccia.
+
Le variabili utilizzate in questa fase si basano sull'hardware del server e sull'ambiente di rete. Le variabili includono `IPADDR` e. `GATEWAY`. Queste sono istruzioni di esempio per SLES e RHEL:

+
*SLES 12 e SLES 15*

+
Creare il file di esempio `/etc/sysconfig/network/ifcfg-eth4` con i seguenti contenuti.

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.1.87/24'
GATEWAY='192.168.1.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
Quindi, creare il file di esempio `/etc/sysconfig/network/ifcfg-eth5`:

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.2.87/24'
GATEWAY='192.168.2.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
*RHEL 7 o RHEL 8*

+
Creare il file di esempio `/etc/sysconfig/network-scripts/ifcfg-eth4` con i seguenti contenuti.

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.1.87/24’
GATEWAY='192.168.1.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
Quindi, creare il file di esempio `/etc/sysconfig/network-scripts/ifcfg-eth5`:

+
[listing]
----
BOOTPROTO='static'
BROADCAST=
ETHTOOL_OPTIONS=
IPADDR='192.168.2.87/24'
GATEWAY='192.168.2.1'
MTU=
NAME='MT27800 Family [ConnectX-5]'
NETWORK=
REMOTE_IPADDR=
STARTMODE='auto'
----
+
*RHEL 9*

+
Utilizzare `nmtui` per attivare e modificare una connessione. Di seguito è riportato un file di esempio `/etc/NetworkManager/system-connections/eth4.nmconnection` il tool genera:

+
[listing]
----

[connection]
id=eth4
uuid=<unique uuid>
type=ethernet
interface-name=eth4

[ethernet]
mtu=4200

[ipv4]
address1=192.168.1.87/24
method=manual

[ipv6]
addr-gen-mode=default
method=auto

[proxy]
----
+
Di seguito è riportato un file di esempio `/etc/NetworkManager/system-connections/eth5.nmconnection` il tool genera:

+
[listing]
----

[connection]
id=eth5
uuid=<unique uuid>
type=ethernet
interface-name=eth5

[ethernet]
mtu=4200

[ipv4]
address1=192.168.2.87/24
method=manual

[ipv6]
addr-gen-mode=default
method=auto

[proxy]
----
. Abilitare le interfacce di rete:
+
[listing]
----

# ifup eth4
# ifup eth5
----
. Impostare il livello NVMe-of sull'host. Creare il seguente file in `/etc/modules-load.d/` per caricare `nvme_rdma` kernel e assicurarsi che il modulo kernel sia sempre attivo, anche dopo un riavvio:
+
[listing]
----

# cat /etc/modules-load.d/nvme_rdma.conf
  nvme_rdma
----
. Riavviare l'host.
+
Per verificare `nvme_rdma` kernel module è stato caricato, eseguire questo comando:

+
[listing]
----
# lsmod | grep nvme
nvme_rdma              36864  0
nvme_fabrics           24576  1 nvme_rdma
nvme_core             114688  5 nvme_rdma,nvme_fabrics
rdma_cm               114688  7 rpcrdma,ib_srpt,ib_srp,nvme_rdma,ib_iser,ib_isert,rdma_ucm
ib_core               393216  15 rdma_cm,ib_ipoib,rpcrdma,ib_srpt,ib_srp,nvme_rdma,iw_cm,ib_iser,ib_umad,ib_isert,rdma_ucm,ib_uverbs,mlx5_ib,qedr,ib_cm
t10_pi                 16384  2 sd_mod,nvme_core
----

